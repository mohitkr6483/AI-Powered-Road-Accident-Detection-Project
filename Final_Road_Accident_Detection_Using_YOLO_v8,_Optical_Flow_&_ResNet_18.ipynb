{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitkr6483/AI-Powered-Road-Accident-Detection-Project/blob/main/Final_Road_Accident_Detection_Using_YOLO_v8%2C_Optical_Flow_%26_ResNet_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XZSAfjq7T_Lw",
        "outputId": "ee3b2c32-e5dd-4821-c706-7c13a2e12120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cpu\n",
            "\n",
            "================ IMAGE MODEL OPTION ================\n",
            "1 → Use SAVED pretrained image model (Kaggle-trained)\n",
            "2 → TRAIN / RETRAIN image model using Kaggle dataset\n",
            "====================================================\n",
            "Enter choice (1 / 2 ): 1\n",
            "\n",
            " Loaded saved pretrained image model.\n",
            " Model path: /content/drive/MyDrive/accident_detection_cache/image_accident_classifier.pth\n",
            "\n",
            "\n",
            "1 → Upload video\n",
            "2 → Enter video URL\n",
            "3 → Exit\n",
            "Choose option (1/2/3): 2\n",
            "Enter video URL: https://www.youtube.com/shorts/SlP5KfKzTpw\n",
            "Analyzing frame: 474/476\n",
            "Analysis completed.\n",
            "\n",
            "===== ACCIDENT ANALYSIS RESULT =====\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Event_ID</th>\n",
              "      <th>Start_Time</th>\n",
              "      <th>End_Time</th>\n",
              "      <th>Start_Frame</th>\n",
              "      <th>End_Frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>00:11</td>\n",
              "      <td>00:12</td>\n",
              "      <td>333</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 → Upload video\n",
            "2 → Enter video URL\n",
            "3 → Exit\n",
            "Choose option (1/2/3): 2\n",
            "Enter video URL: https://www.youtube.com/shorts/19_SNUN9fsQ\n",
            "Analyzing frame: 450/451\n",
            "Analysis completed.\n",
            "\n",
            "===== ACCIDENT ANALYSIS RESULT =====\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Event_ID</th>\n",
              "      <th>Start_Time</th>\n",
              "      <th>End_Time</th>\n",
              "      <th>Start_Frame</th>\n",
              "      <th>End_Frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>00:03</td>\n",
              "      <td>00:03</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>00:10</td>\n",
              "      <td>00:10</td>\n",
              "      <td>303</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 → Upload video\n",
            "2 → Enter video URL\n",
            "3 → Exit\n",
            "Choose option (1/2/3): 2\n",
            "Enter video URL: https://www.youtube.com/watch?v=PgqQPIwNAGQ\n",
            "Analyzing frame: 2976/2978\n",
            "Analysis completed.\n",
            "\n",
            "===== ACCIDENT ANALYSIS RESULT =====\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Event_ID</th>\n",
              "      <th>Start_Time</th>\n",
              "      <th>End_Time</th>\n",
              "      <th>Start_Frame</th>\n",
              "      <th>End_Frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>01:43</td>\n",
              "      <td>01:53</td>\n",
              "      <td>2586</td>\n",
              "      <td>2829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 → Upload video\n",
            "2 → Enter video URL\n",
            "3 → Exit\n",
            "Choose option (1/2/3): 2\n",
            "Enter video URL: https://www.youtube.com/watch?v=0wOcBa3auXM\n",
            "Analyzing frame: 603/604\n",
            "Analysis completed.\n",
            "\n",
            "===== ACCIDENT ANALYSIS RESULT =====\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Event_ID</th>\n",
              "      <th>Start_Time</th>\n",
              "      <th>End_Time</th>\n",
              "      <th>Start_Frame</th>\n",
              "      <th>End_Frame</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>00:13</td>\n",
              "      <td>00:13</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>00:18</td>\n",
              "      <td>00:18</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>00:39</td>\n",
              "      <td>00:39</td>\n",
              "      <td>582</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 → Upload video\n",
            "2 → Enter video URL\n",
            "3 → Exit\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Road ACCIDENTS DETECTION In Pre-recorded Videos\n",
        "# ============================================================\n",
        "#\n",
        "# BASE PRETRAINED MODELS USED:\n",
        "#\n",
        "# 1) YOLOv8n (Ultralytics)\n",
        "#    - Pretrained on COCO dataset\n",
        "#    - Used for real-time object detection (cars, bikes, people, trucks, poles)\n",
        "#\n",
        "# 2) ResNet-18 (TorchVision)\n",
        "#    - Pretrained on ImageNet\n",
        "#    - Fine-tuned on Kaggle accident image dataset\n",
        "#    - Used as image-level accident classifier (optional)\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "!pip install -q opencv-python-headless ultralytics yt-dlp pandas numpy torch torchvision scikit-learn\n",
        "\n",
        "import cv2, os, uuid, subprocess, gc, sys\n",
        "import numpy as np, pandas as pd, torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, datasets, transforms\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files, drive\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURABLE PARAMETERS\n",
        "# ============================================================\n",
        "GLOBAL_STD_FACTOR = 2.0\n",
        "FRAME_STRIDE = 3\n",
        "MERGE_GAP_SECONDS = 4.0\n",
        "EPSILON = 0.000001\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/accident_detection_cache\"\n",
        "KAGGLE_DATASET_DIR = f\"{DRIVE_ROOT}/kaggle_dataset\"\n",
        "MODEL_PATH = f\"{DRIVE_ROOT}/image_accident_classifier.pth\"\n",
        "\n",
        "# ============================================================\n",
        "# SETUP\n",
        "# ============================================================\n",
        "drive.mount(\"/content/drive\")\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ============================================================\n",
        "# YOLO MODEL (ALWAYS USED)\n",
        "# ============================================================\n",
        "yolo = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# ============================================================\n",
        "# IMAGE MODEL SELECTION (ALWAYS ASK)\n",
        "# ============================================================\n",
        "print(\"\\n================ IMAGE MODEL OPTION ================\")\n",
        "print(\"1 → Use SAVED pretrained image model (Kaggle-trained)\")\n",
        "print(\"2 → TRAIN / RETRAIN image model using Kaggle dataset\")\n",
        "#print(\"3 → SKIP image model completely\")\n",
        "print(\"====================================================\")\n",
        "\n",
        "while True:\n",
        "    img_choice = input(\"Enter choice (1 / 2 ): \").strip()\n",
        "    if img_choice in (\"1\", \"2\", \"3\"):\n",
        "        break\n",
        "    print(\"Invalid input. Please choose 1, 2, or 3.\\n\")\n",
        "\n",
        "use_image_model = False\n",
        "img_model = None\n",
        "\n",
        "# ============================================================\n",
        "# IMAGE MODEL SETUP\n",
        "# ============================================================\n",
        "if img_choice != \"3\":\n",
        "    img_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "    img_model.fc = nn.Linear(img_model.fc.in_features, 1)\n",
        "    img_model = img_model.to(device)\n",
        "\n",
        "    img_tf = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.485, 0.456, 0.406],\n",
        "            [0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # OPTION 1: USE SAVED MODEL\n",
        "    # --------------------------------------------------------\n",
        "    if img_choice == \"1\":\n",
        "        if not os.path.exists(MODEL_PATH):\n",
        "            print(\"\\n Saved model not found.\")\n",
        "            print(\"Please train the model at least once.\\n\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        img_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "        img_model.eval()\n",
        "        use_image_model = True\n",
        "\n",
        "        print(\"\\n Loaded saved pretrained image model.\")\n",
        "        print(f\" Model path: {MODEL_PATH}\\n\")\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # OPTION 2: TRAIN / RETRAIN (ASK EPOCHS)\n",
        "    # --------------------------------------------------------\n",
        "    elif img_choice == \"2\":\n",
        "        while True:\n",
        "            try:\n",
        "                epochs = int(input(\"Enter number of training epochs: \").strip())\n",
        "                if epochs > 0:\n",
        "                    break\n",
        "                print(\"Epochs must be a positive integer.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter a valid integer.\")\n",
        "\n",
        "        dataset = datasets.ImageFolder(KAGGLE_DATASET_DIR, transform=img_tf)\n",
        "\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_ds, _ = torch.utils.data.random_split(\n",
        "            dataset, [train_size, val_size]\n",
        "        )\n",
        "\n",
        "        train_dl = torch.utils.data.DataLoader(\n",
        "            train_ds, batch_size=32, shuffle=True\n",
        "        )\n",
        "\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        opt = torch.optim.Adam(img_model.parameters(), lr=1e-4)\n",
        "\n",
        "        print(\"\\n Training image classifier...\\n\")\n",
        "        for ep in range(epochs):\n",
        "            img_model.train()\n",
        "            for x, y in train_dl:\n",
        "                x = x.to(device)\n",
        "                y = y.float().unsqueeze(1).to(device)\n",
        "\n",
        "                loss = loss_fn(img_model(x), y)\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            print(f\"Epoch {ep+1}/{epochs} completed\")\n",
        "\n",
        "        torch.save(img_model.state_dict(), MODEL_PATH)\n",
        "        img_model.eval()\n",
        "        use_image_model = True\n",
        "\n",
        "        print(\"\\n Training complete.\")\n",
        "        print(f\" Model saved at: {MODEL_PATH}\\n\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n Image model skipped. Using YOLO + motion only.\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "def entropy(gray_frame):\n",
        "    histogram = cv2.calcHist(\n",
        "        [gray_frame],\n",
        "        [0],\n",
        "        None,\n",
        "        [64],\n",
        "        [0, 256]\n",
        "    )\n",
        "\n",
        "    histogram = histogram / histogram.sum()\n",
        "\n",
        "    EPSILON = 0.000001  # small value to avoid log(0)\n",
        "    entropy_value = -np.sum(histogram * np.log2(histogram + EPSILON))\n",
        "\n",
        "    return entropy_value\n",
        "\n",
        "def optical_flow(prev_frame, curr_frame):\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_frame, curr_frame, None,\n",
        "                                        0.5, 2, 9, 2, 5, 1.1, 0)\n",
        "\n",
        "    horizontal_motion = flow[:, :, 0]\n",
        "    vertical_motion = flow[:, :, 1]\n",
        "\n",
        "    motion_strength, _ = cv2.cartToPolar(horizontal_motion, vertical_motion)\n",
        "\n",
        "    average_motion = motion_strength.mean()\n",
        "    return average_motion\n",
        "\n",
        "def format_mm_ss(sec):\n",
        "    sec = int(round(sec))\n",
        "    return f\"{sec//60:02d}:{sec%60:02d}\"\n",
        "\n",
        "def infer_accident_description(labels):\n",
        "    s = set(labels)\n",
        "    if \"car\" in s and \"motorcycle\" in s: return \"Car hit bike\"\n",
        "    if \"car\" in s and \"person\" in s: return \"Car hit pedestrian\"\n",
        "    if \"truck\" in s and \"car\" in s: return \"Truck hit car\"\n",
        "    if \"car\" in s and \"truck\" in s: return \"Car hit truck\"\n",
        "    if \"car\" in s: return \"Car crashed\"\n",
        "    if \"truck\" in s: return \"Truck crashed\"\n",
        "    return \"Traffic accident detected\"\n",
        "\n",
        "# ============================================================\n",
        "# EVENT DETECTION (NO DUPLICATES)\n",
        "# ============================================================\n",
        "def detect_events(frame_scores, fps):\n",
        "    frames = np.array([f for f,_,_ in frame_scores])\n",
        "    scores = np.array([s for _,s,_ in frame_scores])\n",
        "\n",
        "    threshold = scores.mean() + GLOBAL_STD_FACTOR * scores.std()\n",
        "\n",
        "    events, current, last = [], None, None\n",
        "    for f, s in zip(frames, scores):\n",
        "        if s > threshold:\n",
        "            if current is None:\n",
        "                current = {\"start\": f, \"end\": f}\n",
        "            elif (f - last) / fps <= MERGE_GAP_SECONDS:\n",
        "                current[\"end\"] = f\n",
        "            else:\n",
        "                events.append(current)\n",
        "                current = {\"start\": f, \"end\": f}\n",
        "            last = f\n",
        "        else:\n",
        "            if current and (f - last) / fps > MERGE_GAP_SECONDS:\n",
        "                events.append(current)\n",
        "                current = None\n",
        "\n",
        "    if current:\n",
        "        events.append(current)\n",
        "\n",
        "    return list({(e[\"start\"], e[\"end\"]): e for e in events}.values())\n",
        "\n",
        "# ============================================================\n",
        "# VIDEO ANALYSIS\n",
        "# ============================================================\n",
        "def analyze(video):\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "\n",
        "    ret, prev = cap.read()\n",
        "    if not ret:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "    frame_scores, frame_labels = [], {}\n",
        "    idx = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        idx += 1\n",
        "\n",
        "        # APPLY FRAME STRIDE (FIX)\n",
        "        if idx % FRAME_STRIDE != 0:\n",
        "            prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            continue\n",
        "\n",
        "        print(f\"\\rAnalyzing frame: {idx}/{total}\", end=\"\", flush=True)\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        flow = optical_flow(prev_gray, gray)\n",
        "        ent = entropy(gray)\n",
        "\n",
        "        res = yolo(frame, conf=0.25, verbose=False)[0]\n",
        "        labels = [yolo.model.names[int(c)] for c in res.boxes.cls] if res.boxes else []\n",
        "\n",
        "        score = 3.0 * flow + 2.2 * ent + len(labels)\n",
        "        frame_scores.append((idx, score, labels))\n",
        "        frame_labels[idx] = labels\n",
        "\n",
        "        prev_gray = gray\n",
        "\n",
        "    cap.release()\n",
        "    print(\"\\nAnalysis completed.\")\n",
        "\n",
        "    events = detect_events(frame_scores, fps)\n",
        "\n",
        "    if not events:\n",
        "        return pd.DataFrame([{\n",
        "            \"Event_ID\": \"-\",\n",
        "            \"Start_Time\": \"-\",\n",
        "            \"End_Time\": \"-\",\n",
        "            \"Start_Frame\": \"-\",\n",
        "            \"End_Frame\": \"-\"\n",
        "        }])\n",
        "\n",
        "    rows = []\n",
        "    for i, e in enumerate(events, 1):\n",
        "        sf, ef = e[\"start\"], e[\"end\"]\n",
        "        labels = []\n",
        "        for f in range(sf, ef + 1):\n",
        "            labels.extend(frame_labels.get(f, []))\n",
        "\n",
        "        rows.append({\n",
        "            \"Event_ID\": i,\n",
        "            \"Start_Time\": format_mm_ss(sf / fps),\n",
        "            \"End_Time\": format_mm_ss(ef / fps),\n",
        "            \"Start_Frame\": sf,\n",
        "            \"End_Frame\": ef\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ============================================================\n",
        "# MAIN MENU\n",
        "# ============================================================\n",
        "while True:\n",
        "    print(\"\\n1 → Upload video\")\n",
        "    print(\"2 → Enter video URL\")\n",
        "    print(\"3 → Exit\")\n",
        "\n",
        "    choice = input(\"Choose option (1/2/3): \").strip()\n",
        "    if choice not in (\"1\",\"2\",\"3\"):\n",
        "        print(\"Invalid input.\")\n",
        "        continue\n",
        "    if choice == \"3\":\n",
        "        print(\"Exiting.\")\n",
        "        break\n",
        "\n",
        "    if choice == \"1\":\n",
        "        up = files.upload()\n",
        "        video = \"/content/\" + next(iter(up))\n",
        "    else:\n",
        "        url = input(\"Enter video URL: \").strip()\n",
        "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sid = uuid.uuid4().hex[:6]\n",
        "        out = f\"/content/video_{ts}_{sid}.%(ext)s\"\n",
        "        subprocess.run([\"yt-dlp\",\"-f\",\"best\",\"-o\",out,url])\n",
        "        video = [f\"/content/{f}\" for f in os.listdir(\"/content\")\n",
        "                 if f.startswith(f\"video_{ts}_{sid}\")][0]\n",
        "\n",
        "    df = analyze(video)\n",
        "\n",
        "    print(\"\\n===== ACCIDENT ANALYSIS RESULT =====\\n\")\n",
        "    display(HTML(df.to_html(index=False)))\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n"
      ]
    }
  ]
}